%DQN:
@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}


%rainbow:  1710.02298
@article{matteo2017rainbow,
  title={Rainbow: Combining Improvements in Deep Reinforcement learning},
  author={Matteo, H and Joseph, M and Hado, H and Tom, S and Georg, O and Will, D and Dan, H and Bilal, P and Mohammad, A and David, S},
  journal={arXiv: 1710.02298 v1 [cs. AI]},
  year={2017}
}

%sutton2018:
@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

%LeCun etal 2015:
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

%Schmidhuber 2015:
@article{schmidhuber2015deep,
  title={Deep learning in neural networks: An overview},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural networks},
  volume={61},
  pages={85--117},
  year={2015},
  publisher={Elsevier}
}

%Goodfellow 2016：
@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}


%Mnih 2015:--->%DQN:


%Alphago:
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

%{2} chess and Shogi by the selfplay
@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

%startcraft:
@article{vinyals2019alphastar,
  title={AlphaStar: Mastering the real-time strategy game StarCraft II},
  author={Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojciech M and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and others},
  journal={DeepMind Blog},
  year={2019}
}

%Levine et al.,2016
@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

%Gandhi et al. 2017
@inproceedings{gandhi2017learning,
  title={Learning to fly by crashing},
  author={Gandhi, Dhiraj and Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3948--3955},
  year={2017},
  organization={IEEE}
}


%Pinto et al., 2017
@article{pinto2017asymmetric,
  title={Asymmetric actor critic for image-based robot learning},
  author={Pinto, Lerrel and Andrychowicz, Marcin and Welinder, Peter and Zaremba, Wojciech and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1710.06542},
  year={2017}
}

%YOu et,al 2017 
@article{pan2017virtual,
  title={Virtual to real reinforcement learning for autonomous driving},
  author={Pan, Xinlei and You, Yurong and Wang, Ziyan and Lu, Cewu},
  journal={arXiv preprint arXiv:1704.03952},
  year={2017}
}

%Deng et.al 2017
@article{deng2016deep,
  title={Deep direct reinforcement learning for financial signal representation and trading},
  author={Deng, Yue and Bao, Feng and Kong, Youyong and Ren, Zhiquan and Dai, Qionghai},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={3},
  pages={653--664},
  year={2016},
  publisher={IEEE}
}

%Policy Gradient
@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

%A2C
%A3C
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

%PPO
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


%TRPO
@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

%C51
@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}

%QR-DQN
@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}


%HER
@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5048--5058},
  year={2017}
}

%DDPG
@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}


%TD3
@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

%SAC
@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

%Alpha Zero-->%{2} chess and Shogi by the selfplay

%Markov Decision Processes
@book{puterman2014markov,
  title={Markov Decision Processes.: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}


%Bellman equation: 不要


%Abhijit Gosavi
@article{gosavi2009reinforcement,
  title={Reinforcement learning: A tutorial survey and recent advances},
  author={Gosavi, Abhijit},
  journal={INFORMS Journal on Computing},
  volume={21},
  number={2},
  pages={178--192},
  year={2009},
  publisher={INFORMS}
}


%Michael L.Littman 1996
@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}

%Aloghrithms for reinforcement learning by szepesvari:
@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}

%1708.05866
@article{arulkumaran2017brief,
  title={A brief survey of deep reinforcement learning},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={arXiv preprint arXiv:1708.05866},
  year={2017}
}

%ranzato2016sequence
@article{ranzato2015sequence,
  title={Sequence level training with recurrent neural networks},
  author={Ranzato, Marc'Aurelio and Chopra, Sumit and Auli, Michael and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1511.06732},
  year={2015}
}


%bahdanau2017actor
@article{bahdanau2016actor,
  title={An actor-critic algorithm for sequence prediction},
  author={Bahdanau, Dzmitry and Brakel, Philemon and Xu, Kelvin and Goyal, Anirudh and Lowe, Ryan and Pineau, Joelle and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1607.07086},
  year={2016}
}

%survey on robot
@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

%watkins1989learning:
@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}


%gordon1996stable:
@inproceedings{gordon1996stable,
  title={Stable fitted reinforcement learning},
  author={Gordon, Geoffrey J},
  booktitle={Advances in neural information processing systems},
  pages={1052--1058},
  year={1996}
}


%bellman1962applied
@article{bellman1962dynamic,
  title={Dynamic programming applied to control processes governed by general functional equations},
  author={Bellman, Richard and Kalaba, Robert},
  journal={Proceedings of the National Academy of Sciences of the United States of America},
  volume={48},
  number={10},
  pages={1735},
  year={1962},
  publisher={National Academy of Sciences}
}

%riedmiller2005neural
@inproceedings{riedmiller2005neural,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}


%baird1995residual
@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}

%tsitsiklis1997analysis
@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1075--1081},
  year={1997}
}

%gordon1999approximate
@article{gordon1999approximate,
  title={Approximate solutions to Markov decision processes},
  author={Gordon, Geoffrey J},
  year={1999},
  publisher={figshare}
}

%van2016deep
@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Thirtieth AAAI conference on artificial intelligence},
  year={2016}
}

%mnih2015human
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}


%Arcade Learning Enviroment ALE:
@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

%hasselt2010double--->van2016deep


%wang2016dueling
@article{wang2015dueling,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2015}
}


%schau12015prioritized1
@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}


%mnih2016asynchronous
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

%bellemare2017distributional--check1811.12560
@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}


%dabney2017distributional
@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

%rowland2018analysis
@article{rowland2018analysis,
  title={An analysis of categorical distributional reinforcement learning},
  author={Rowland, Mark and Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1802.08163},
  year={2018}
}

%morimura2010nonparametric
@inproceedings{morimura2010nonparametric,
  title={Nonparametric return distribution approximation for reinforcement learning},
  author={Morimura, Tetsuro and Sugiyama, Masashi and Kashima, Hisashi and Hachiya, Hirotaka and Tanaka, Toshiyuki},
  booktitle={Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
  pages={799--806},
  year={2010}
}

%fortunato2018noisy1

@article{fortunato2017noisy,
  title={Noisy networks for exploration},
  author={Fortunato, Meire and Azar, Mohammad Gheshlaghi and Piot, Bilal and Menick, Jacob and Osband, Ian and Graves, Alex and Mnih, Vlad and Munos, Remi and Hassabis, Demis and Pietquin, Olivier and others},
  journal={arXiv preprint arXiv:1706.10295},
  year={2017}
}

@article{mahajan2017symmetry,
  title={Symmetry learning for function approximation in reinforcement learning},
  author={Mahajan, Anuj and Tulabandhula, Theja},
  journal={arXiv preprint arXiv:1706.02999},
  year={2017}
}

@article{sendonaris2017learning,
  title={Learning from demonstrations for real world reinforcement learning},
  author={Sendonaris, Andrew and Dulac-Arnold, COM Gabriel},
  journal={arXiv preprint arXiv:1704.03732},
  year={2017}
}

@inproceedings{taitler2017learning,
  title={Learning control for air hockey striking using deep reinforcement learning},
  author={Taitler, Ayal and Shimkin, Nahum},
  booktitle={2017 International Conference on Control, Artificial Intelligence, Robotics \& Optimization (ICCAIRO)},
  pages={22--27},
  year={2017},
  organization={IEEE}
}

@inproceedings{levine2017shallow,
  title={Shallow updates for deep reinforcement learning},
  author={Levine, Nir and Zahavy, Tom and Mankowitz, Daniel J and Tamar, Aviv and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3135--3145},
  year={2017}
}

@article{lipton2016efficient,
  title={Efficient exploration for dialogue policy learning with bbq networks \& replay buffer spiking},
  author={Lipton, Zachary C and Gao, Jianfeng and Li, Lihong and Li, Xiujun and Ahmed, Faisal and Deng, Li},
  journal={arXiv preprint arXiv:1608.05081},
  volume={3},
  year={2016}
}

@article{leibfried2017information,
  title={An information-theoretic optimality principle for deep reinforcement learning},
  author={Leibfried, Felix and Grau-Moya, Jordi and Bou-Ammar, Haitham},
  journal={arXiv preprint arXiv:1708.01867},
  year={2017}
}

@article{mossalam2016multi,
  title={Multi-objective deep reinforcement learning},
  author={Mossalam, Hossam and Assael, Yannis M and Roijers, Diederik M and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1610.02707},
  year={2016}
}

@article{roijers2015computing,
  title={Computing convex coverage sets for faster multi-objective coordination},
  author={Roijers, Diederik Marijn and Whiteson, Shimon and Oliehoek, Frans A},
  journal={Journal of Artificial Intelligence Research},
  volume={52},
  pages={399--443},
  year={2015}
}

@inproceedings{anschel2017averaged,
  title={Averaged-dqn: Variance reduction and stabilization for deep reinforcement learning},
  author={Anschel, Oron and Baram, Nir and Shimkin, Nahum},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={176--185},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{hausknecht2015deep,
  title={Deep recurrent q-learning for partially observable mdps},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={2015 AAAI Fall Symposium Series},
  year={2015}
}


@article{zhu2017improving,
  title={On improving deep reinforcement learning for pomdps},
  author={Zhu, Pengfei and Li, Xin and Poupart, Pascal and Miao, Guanghui},
  journal={arXiv preprint arXiv:1704.07978},
  year={2017}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4026--4034},
  year={2016}
}
@inproceedings{jaques2017sequence,
  title={Sequence tutor: Conservative fine-tuning of sequence generation models with kl-control},
  author={Jaques, Natasha and Gu, Shixiang and Bahdanau, Dzmitry and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Turner, Richard E and Eck, Douglas},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1645--1654},
  year={2017},
  organization={JMLR. org}
}

@article{nair2015massively,
  title={Massively parallel methods for deep reinforcement learning},
  author={Nair, Arun and Srinivasan, Praveen and Blackwell, Sam and Alcicek, Cagdas and Fearon, Rory and De Maria, Alessandro and Panneershelvam, Vedavyas and Suleyman, Mustafa and Beattie, Charles and Petersen, Stig and others},
  journal={arXiv preprint arXiv:1507.04296},
  year={2015}
}

@article{sorokin2015deep,
  title={Deep attention recurrent Q-network},
  author={Sorokin, Ivan and Seleznev, Alexey and Pavlov, Mikhail and Fedorov, Aleksandr and Ignateva, Anastasiia},
  journal={arXiv preprint arXiv:1512.01693},
  year={2015}
}

@article{lipton2016combating,
  title={Combating reinforcement learning's sisyphean curse with intrinsic fear},
  author={Lipton, Zachary C and Azizzadenesheli, Kamyar and Kumar, Abhishek and Li, Lihong and Gao, Jianfeng and Deng, Li},
  journal={arXiv preprint arXiv:1611.01211},
  year={2016}
}

@inproceedings{gu2016continuous,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={2829--2838},
  year={2016}
}

@article{duryea2016exploring,
  title={Exploring deep reinforcement learning with multi q-learning},
  author={Duryea, Ethan and Ganger, Michael and Hu, Wei},
  journal={Intelligent Control and Automation},
  volume={7},
  number={04},
  pages={129},
  year={2016},
  publisher={Scientific Research Publishing}
}


